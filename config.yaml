model: "llama3.2"
temperature: 0.7
ollama_host: "http://localhost:11434"
# System prompt is loaded from system_prompt.txt (project root).
# Edit that file to customise Milly's behaviour and persona.
# This key is a fallback only â€” used if system_prompt.txt is absent.

guardian:
  max_input_length: 4000
  injection_detection: true
  output_sanitization: true
  log_detections: true

memory:
  enabled: true
  max_history: 50

rag:
  enabled: true
  max_file_size_mb: 10
  scan_for_injection: true
  top_k: 3
